{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADM\\.conda\\envs\\yng6012_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ADM\\.conda\\envs\\yng6012_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ADM\\.conda\\envs\\yng6012_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ADM\\.conda\\envs\\yng6012_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ADM\\.conda\\envs\\yng6012_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ADM\\.conda\\envs\\yng6012_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./hen2048\n",
      "./brain_data8~50\n",
      "action\n",
      "normal\n",
      "action\n",
      "normal\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./hen2048\\0round\\high_ckpt\\0\n",
      "accuracy0.5199004975124378\n",
      "INFO:tensorflow:Restoring parameters from ./hen2048\\0round\\high_ckpt\\0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3110e1e3e64b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlimit_part\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                 \u001b[0mfinal_data_limit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\yng6012_gpu\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     37\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[0;32m     38\u001b[0m           initial=_NoValue, where=True):\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "from tensorflow.nn import rnn_cell\n",
    "import pickle\n",
    "import gzip\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "import brain_python3 as bp\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_times = 201\n",
    "n_frequency = 79\n",
    "n_outputs = 2\n",
    "\n",
    "last_neurons = 40\n",
    "n_neurons = [40,40,last_neurons]\n",
    "limit_part = 1500\n",
    "\n",
    "high_max_load = 1\n",
    "\n",
    "important_index = [105,125]\n",
    "normal_range_index = [20,180]\n",
    "window = 30\n",
    "step = 1\n",
    "\n",
    "learning_rate = 0.001\n",
    "train_keep_prob = 1.0\n",
    "want_round = 9\n",
    "want_loop_percent = 0.9\n",
    "test_keep_prob = 1.0\n",
    "eeg = bp.brain_python(n_times,n_frequency,window,n_outputs,n_neurons, learning_rate)\n",
    "\n",
    "data_base_path_array = [\"./brain_data8~50_2048\",\"./brain_data8~50_1024\"]\n",
    "train_file_path_array = [\"./hen2048\",\"./hen1024\"]\n",
    "\n",
    "for loop in range(len(train_file_path_array)):\n",
    "    train_file_path=train_file_path_array[loop]\n",
    "    data_base_path=data_base_path_array[loop]\n",
    "    print(data_base_path)\n",
    "    print(train_file_path)\n",
    "    \n",
    "    tf.set_random_seed(777)\n",
    "\n",
    "    label_list,label_dic,label_onehot = eeg.label_info(data_base_path)\n",
    "    _,_,test_label_onehot = eeg.label_info(data_base_path)\n",
    "\n",
    "    number_of_round = 0\n",
    "    remain_data = 0\n",
    "\n",
    "    for label_list_name in label_list:\n",
    "        remain_data += len(os.listdir(os.path.join(data_base_path,label_list_name)))\n",
    "\n",
    "    if not os.path.isdir(train_file_path):\n",
    "        os.makedirs(train_file_path)\n",
    "\n",
    "    final_data_path = os.path.join(train_file_path,\"final_data\")\n",
    "\n",
    "    if os.path.isdir(final_data_path):\n",
    "        shutil.rmtree(final_data_path)\n",
    "\n",
    "    os.makedirs(final_data_path)\n",
    "\n",
    "    intersection_array = np.array([])\n",
    "\n",
    "    test_data,test_data_label, number_label = eeg.preprocessing(data_base_path)\n",
    "    train_data,train_data_label,_ = eeg.preprocessing(data_base_path)\n",
    "\n",
    "    test_data = test_data[:,100:130]\n",
    "\n",
    "    test_data=np.swapaxes(test_data,1,2)\n",
    "    test_data=np.flip(test_data,axis=1)\n",
    "    \n",
    "    test_data_limit = np.zeros_like(test_data)\n",
    "    \n",
    "    for i in range(test_data.shape[0]):\n",
    "        for j in np.arange(0,1,1/limit_part):\n",
    "            test_data_limit[i]+=(test_data[i]>=(test_data[i].max()*j))\n",
    "        \n",
    "    while number_of_round<=want_round:\n",
    "\n",
    "        random_pick = random.sample(range(0,train_data.shape[0]),int(train_data.shape[0]*0.5))\n",
    "        final_data = train_data[random_pick]\n",
    "        final_data_label = train_data_label[random_pick]\n",
    "\n",
    "        final_data, final_data_label = eeg.data_multiple(final_data,final_data_label,label_list,important_index,normal_range_index,step)\n",
    "        \n",
    "        final_data=np.swapaxes(final_data,1,2)\n",
    "        final_data=np.flip(final_data,axis=1)\n",
    "        final_data_reverse = np.flip(final_data,axis=2)\n",
    "        \n",
    "        final_data=np.concatenate((final_data,final_data_reverse),axis=0)\n",
    "        final_data_label=np.concatenate((final_data_label,final_data_label),axis=0)\n",
    "        final_data_limit = np.zeros_like(final_data)\n",
    "        \n",
    "        for i in range(final_data.shape[0]):\n",
    "            for j in np.arange(0,1,1/limit_part):\n",
    "                final_data_limit[i]+=(final_data[i]>=(final_data[i].max()*j))\n",
    "\n",
    "        batch_size = int(final_data.shape[0]*0.05)\n",
    "\n",
    "        epoch = 0\n",
    "        last_accuracy = 0.0\n",
    "        convergence_array = np.zeros(standard_convergence)  \n",
    "        saver_high = tf.train.Saver(max_to_keep=high_max_load)\n",
    "        dif_array=np.zeros(batch_size)\n",
    "        acc_array=np.zeros(batch_size)\n",
    "        high_acc_array=np.zeros(batch_size)\n",
    "        last_dif = 0\n",
    "        end_percent = 0\n",
    "\n",
    "        train_round_path = os.path.join(train_file_path,str(number_of_round)+\"round\")\n",
    "        if not os.path.isdir(train_round_path):\n",
    "            os.makedirs(train_round_path)\n",
    "\n",
    "        high_ckpt_path=os.path.join(train_round_path,\"high_ckpt\")\n",
    "        if not os.path.isdir(high_ckpt_path):\n",
    "            os.makedirs(high_ckpt_path)\n",
    "\n",
    "        train_x = np.zeros((batch_size,final_data.shape[1],final_data.shape[2]))\n",
    "        train_y = np.zeros((batch_size,final_data_label.shape[1]))\n",
    "        \n",
    "        print(number_of_round)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            tf.global_variables_initializer().run()\n",
    "\n",
    "            if tf.train.get_checkpoint_state(high_ckpt_path) and tf.train.get_checkpoint_state(high_ckpt_path).model_checkpoint_path:\n",
    "                saver_high.restore(sess, os.path.join(high_ckpt_path,str(number_of_round)))\n",
    "                accuracy,_,_,_,y_pred = eeg.accuracy(sess,test_data_limit,test_data_label, test_keep_prob,label_onehot,test_label_onehot)\n",
    "                print(\"accuracy\"+str(accuracy))\n",
    "\n",
    "            else:\n",
    "                while end_percent<0.98:\n",
    "                    start = time.time()\n",
    "                    avr_loss = 0\n",
    "                    for n in range(final_data.shape[0]//batch_size):\n",
    "                        for i in range(batch_size):\n",
    "                            data_num = random.randint(0,(final_data.shape[0]-1))\n",
    "                            train_x[i] = final_data_limit[data_num,:]\n",
    "                            train_y[i] = final_data_label[data_num]\n",
    "\n",
    "                        loss = eeg.train(sess,train_x,train_y,train_keep_prob)\n",
    "\n",
    "                        avr_loss += loss\n",
    "                        epoch_percentage = int((n+1)*100/(final_data.shape[0]//batch_size))\n",
    "                        print(\"[\"+(\"|\"*epoch_percentage)+(\" \"*(100-epoch_percentage))+\"]\\tSCE: {:6f}\".format(loss),end=\"\\r\")\n",
    "\n",
    "                    avr_loss = avr_loss/(final_data.shape[0]//batch_size)\n",
    "                    print('\\nstep: {:03d}, SCE: {:6f}'.format(epoch, avr_loss))\n",
    "\n",
    "                    accuracy,_,_,_,_ = eeg.accuracy(sess,test_data_limit,test_data_label, test_keep_prob,label_onehot,test_label_onehot)\n",
    "\n",
    "                    if epoch == 0:\n",
    "                        top_sce = avr_loss\n",
    "                        bottom_sce = avr_loss\n",
    "\n",
    "                    if top_sce < avr_loss:\n",
    "                        top_sce = avr_loss\n",
    "                    if bottom_sce > avr_loss:\n",
    "                        bottom_sce = avr_loss\n",
    "\n",
    "                    if (accuracy >= last_accuracy) and (avr_loss<((top_sce+bottom_sce)/2)) :\n",
    "                        last_accuracy = accuracy\n",
    "                        saver_high.save(sess, os.path.join(high_ckpt_path,str(number_of_round)))\n",
    "                        print(\"Save high Model\")\n",
    "\n",
    "#                     if (epoch%25 is 24) and (avr_loss<((top_sce+bottom_sce)/2)):\n",
    "#                         saver_high.save(sess, os.path.join(high_ckpt_path,str(number_of_round)))\n",
    "\n",
    "                    ref_dif = last_accuracy/10\n",
    "                    acc_array[epoch%batch_size] = accuracy\n",
    "                    high_acc_array[epoch%batch_size] = last_accuracy\n",
    "\n",
    "                    dif = (sum(acc_array)/batch_size)*(sum(high_acc_array)/batch_size+1)\n",
    "                    dif_array[epoch%batch_size]=dif-last_dif\n",
    "                    last_dif = dif\n",
    "\n",
    "                    convergence_array[epoch%standard_convergence] = ref_dif>sum(dif_array)\n",
    "                    end_percent = sum(convergence_array)/standard_convergence\n",
    "                    epoch += 1\n",
    "                    end = time.time()\n",
    "                    print('Round : {},accuracy: {:6f}, epoch time: {:6f}, end_percnet: {:6f}'.format(number_of_round,accuracy,end-start,end_percent))\n",
    "\n",
    "            saver_high.restore(sess, os.path.join(high_ckpt_path,str(number_of_round)))\n",
    "            _,correct_index,_,_,_ = eeg.accuracy(sess,test_data_limit,test_data_label, test_keep_prob,label_onehot,test_label_onehot)\n",
    "            success_data_path = os.path.join(train_round_path,\"success_data\")\n",
    "\n",
    "            if os.path.isdir(success_data_path):\n",
    "                shutil.rmtree(success_data_path)\n",
    "\n",
    "            os.makedirs(success_data_path)\n",
    "\n",
    "            for label_name in label_list:\n",
    "                os.makedirs(os.path.join(success_data_path,label_name))\n",
    "\n",
    "            for i in correct_index:\n",
    "                start_path=os.path.join(data_base_path,label_onehot[np.argmax(test_data_label[i])],number_label[i])\n",
    "                arrive_path=os.path.join(success_data_path,label_onehot[np.argmax(test_data_label[i])])\n",
    "                shutil.copy(start_path,arrive_path)\n",
    "\n",
    "            intersection_array = np.append(intersection_array,success_data_path)\n",
    "\n",
    "            number_of_round += 1\n",
    "\n",
    "    for label_list_name in label_list:\n",
    "        final_path=os.path.join(final_data_path,label_list_name)\n",
    "        if os.path.isdir(final_path):\n",
    "            shutil.rmtree(final_path)\n",
    "        os.makedirs(final_path)\n",
    "        intersection_data = np.array([])\n",
    "        for path in intersection_array:\n",
    "            intersection_data=np.append(intersection_data,os.listdir(os.path.join(path,label_list_name)))\n",
    "        unique, counts = np.unique(intersection_data, return_counts=True)\n",
    "        for i,j in zip(unique, counts):\n",
    "            if j>=int((want_round+1)*want_loop_percent):\n",
    "                shutil.copy(os.path.join(data_base_path,label_list_name,i),final_path)\n",
    "\n",
    "    #마지막 학습\n",
    "\n",
    "    train_data,train_data_label,_ = eeg.preprocessing(final_data_path)\n",
    "    test_data,test_data_label, number_label = eeg.preprocessing(data_base_path)\n",
    "\n",
    "    final_data, final_data_label = eeg.data_multiple(train_data,train_data_label,label_list,important_index,normal_range_index,step)\n",
    "    test_data = test_data[:,100:130]\n",
    "    \n",
    "    final_data=np.swapaxes(final_data,1,2)\n",
    "    final_data=np.flip(final_data,axis=1)\n",
    "    final_data_reverse = np.flip(final_data,axis=2)\n",
    "    final_data=np.concatenate((final_data,final_data_reverse),axis=0)\n",
    "    final_data_label=np.concatenate((final_data_label,final_data_label),axis=0)\n",
    "    final_data_limit = np.zeros_like(final_data)\n",
    "    \n",
    "    \n",
    "    test_data=np.swapaxes(test_data,1,2)\n",
    "    test_data=np.flip(test_data,axis=1)\n",
    "    test_data_limit = np.zeros_like(test_data)\n",
    "    \n",
    "    for i in range(final_data.shape[0]):\n",
    "        for j in np.arange(0,1,1/limit_part):\n",
    "            final_data_limit[i]=(final_data[i]>=(final_data[i].max()*j))\n",
    "\n",
    "    for i in range(test_data.shape[0]):\n",
    "        for j in np.arange(0,1,1/limit_part):\n",
    "            test_data_limit[i]=(test_data[i]>=(test_data[i].max()*j))\n",
    "\n",
    "    batch_size = int(final_data.shape[0]*0.05)\n",
    "\n",
    "    epoch = 0\n",
    "    last_accuracy = 0.0\n",
    "    convergence_array = np.zeros(standard_convergence)  \n",
    "    saver_high = tf.train.Saver(max_to_keep=high_max_load)\n",
    "    dif_array=np.zeros(batch_size)\n",
    "    acc_array=np.zeros(batch_size)\n",
    "    high_acc_array=np.zeros(batch_size)\n",
    "    last_dif = 0\n",
    "    end_percent = 0\n",
    "\n",
    "    train_round_path = os.path.join(train_file_path,\"final round\")\n",
    "    if not os.path.isdir(train_round_path):\n",
    "        os.makedirs(train_round_path)\n",
    "\n",
    "    high_ckpt_path=os.path.join(train_round_path,\"high_ckpt\")\n",
    "    if not os.path.isdir(high_ckpt_path):\n",
    "        os.makedirs(high_ckpt_path)\n",
    "\n",
    "    train_x = np.zeros((batch_size,final_data.shape[1],final_data.shape[2]))\n",
    "    train_y = np.zeros((batch_size,final_data_label.shape[1]))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        if tf.train.get_checkpoint_state(high_ckpt_path) and tf.train.get_checkpoint_state(high_ckpt_path).model_checkpoint_path:\n",
    "            pass\n",
    "\n",
    "        else:  \n",
    "            while end_percent<0.98:\n",
    "                start = time.time()\n",
    "                avr_loss = 0\n",
    "                for n in range(final_data.shape[0]//batch_size):\n",
    "                    for i in range(batch_size):\n",
    "                        data_num = random.randint(0,(final_data.shape[0]-1))\n",
    "                        train_x[i] = final_data_limit[data_num,:]\n",
    "                        train_y[i] = final_data_label[data_num]\n",
    "\n",
    "                    loss = eeg.train(sess,train_x,train_y,train_keep_prob)\n",
    "\n",
    "                    avr_loss += loss\n",
    "                    epoch_percentage = int((n+1)*100/(final_data.shape[0]//batch_size))\n",
    "                    print(\"[\"+(\"|\"*epoch_percentage)+(\" \"*(100-epoch_percentage))+\"]\\tSCE: {:6f}\".format(loss),end=\"\\r\")\n",
    "\n",
    "                avr_loss = avr_loss/(final_data.shape[0]//batch_size)\n",
    "                print('\\nstep: {:03d}, SCE: {:6f}'.format(epoch, avr_loss))\n",
    "\n",
    "                accuracy,_,_,_,y_pred = eeg.accuracy(sess,test_data_limit,test_data_label, test_keep_prob,label_onehot,test_label_onehot)\n",
    "\n",
    "                if epoch == 0:\n",
    "                    top_sce = avr_loss\n",
    "                    bottom_sce = avr_loss\n",
    "\n",
    "                if top_sce < avr_loss:\n",
    "                    top_sce = avr_loss\n",
    "                if bottom_sce > avr_loss:\n",
    "                    bottom_sce = avr_loss\n",
    "\n",
    "                if (accuracy >= last_accuracy) and (avr_loss<((top_sce+bottom_sce)/2)) :\n",
    "                    last_accuracy = accuracy\n",
    "                    saver_high.save(sess, os.path.join(high_ckpt_path,str(number_of_round)))\n",
    "                    print(\"Save high Model\")\n",
    "\n",
    "                ref_dif = last_accuracy/10\n",
    "                acc_array[epoch%batch_size] = accuracy\n",
    "                high_acc_array[epoch%batch_size] = last_accuracy\n",
    "\n",
    "                dif = (sum(acc_array)/batch_size)*(sum(high_acc_array)/batch_size+1)\n",
    "                dif_array[epoch%batch_size]=dif-last_dif\n",
    "                last_dif = dif\n",
    "\n",
    "                convergence_array[epoch%standard_convergence] = ref_dif>sum(dif_array)\n",
    "                end_percent = sum(convergence_array)/standard_convergence\n",
    "                epoch += 1\n",
    "                end = time.time()\n",
    "                print('Round : {},accuracy: {:6f}, epoch time: {:6f}, end_percnet: {:6f}'.format(number_of_round,accuracy,end-start,end_percent))\n",
    "\n",
    "        saver_high.restore(sess, os.path.join(high_ckpt_path,str(number_of_round)))\n",
    "        _,correct_index,fail_index,unknown_index,_ = eeg.accuracy(sess,test_data_limit,test_data_label, test_keep_prob,label_onehot,test_label_onehot)\n",
    "        success_data_path = os.path.join(train_round_path,\"success_data\")\n",
    "        fail_data_path = os.path.join(train_round_path,\"fail_data\")\n",
    "        unknown_data_path = os.path.join(train_round_path,\"unknown_data\")\n",
    "\n",
    "        final_round_path=[success_data_path,fail_data_path,unknown_data_path]\n",
    "        final_round_index=[correct_index,fail_index,unknown_index]\n",
    "\n",
    "        for i,j in zip(final_round_path,final_round_index):\n",
    "            if os.path.isdir(i):\n",
    "                shutil.rmtree(i)\n",
    "            os.makedirs(i)\n",
    "\n",
    "            for label_name in label_list:\n",
    "                os.makedirs(os.path.join(i,label_name))\n",
    "\n",
    "            for index in j:\n",
    "                start_path=os.path.join(data_base_path,label_onehot[np.argmax(test_data_label[index])],number_label[index])\n",
    "                arrive_path=os.path.join(i,label_onehot[np.argmax(test_data_label[index])])\n",
    "                shutil.copy(start_path,arrive_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
