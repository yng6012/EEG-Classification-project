{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df7d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "from tensorflow.nn import rnn_cell\n",
    "import pickle\n",
    "import gzip\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "import brain_python4 as bp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "n_times = 201\n",
    "n_frequency = 79\n",
    "n_outputs = 2\n",
    "\n",
    "last_neurons = 40\n",
    "n_neurons = [40,40,last_neurons]\n",
    "\n",
    "want_accuracy = 1.1\n",
    "last_accuracy = 0\n",
    "\n",
    "max_load = 5\n",
    "high_max_load = 10\n",
    "\n",
    "load_number = ''\n",
    "\n",
    "important_index = [105,125]\n",
    "normal_range_index = [20,180]\n",
    "window = 30\n",
    "step = 1\n",
    "\n",
    "learning_rate = 0.001\n",
    "train_keep_prob = 0.5\n",
    "test_keep_prob = 1.0\n",
    "n_epochs = 20001\n",
    "\n",
    "data_base_path = \"./brain_data8~50\"\n",
    "test_data_base_path = \"./brain_data8~50_t\"\n",
    "ckpt_base_path = \"./ckpt/\"\n",
    "high_weight_path_base = \"./ckpt/high/\"\n",
    "\n",
    "eeg = bp.brain_python(n_times,n_frequency,window,n_outputs,n_neurons, learning_rate)\n",
    "label_list,_,_ = eeg.label_info(data_base_path)\n",
    "test_label_list,_,_ = eeg.label_info(test_data_base_path)\n",
    "train_data,train_data_label,_ = eeg.preprocessing(data_base_path)\n",
    "test_data,test_data_label,_ = eeg.preprocessing(test_data_base_path,equal_count_data=False)\n",
    "\n",
    "test_data = test_data[:,100:130]\n",
    "final_data, final_data_label = eeg.data_multiple(train_data,train_data_label,label_list,important_index,normal_range_index,step)\n",
    "\n",
    "final_data=np.swapaxes(final_data,1,2)\n",
    "final_data=np.flip(final_data,axis=1)\n",
    "final_data_reverse = np.flip(final_data,axis=2)\n",
    "\n",
    "final_data=np.concatenate((final_data,final_data_reverse),axis=0)\n",
    "final_data_label=np.concatenate((final_data_label,final_data_label),axis=0)\n",
    "\n",
    "test_data=np.swapaxes(test_data,1,2)\n",
    "test_data=np.flip(test_data,axis=1)\n",
    "\n",
    "batch_size = int(final_data.shape[0]*0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997521fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN 데이터가 있을 경우 실행\n",
    "normal_array = np.load('./gan_normal_file3/saved_0.npy')\n",
    "normal_label = final_data_label[-1]\n",
    "for _ in range(4):\n",
    "    normal_label = np.concatenate((normal_label,final_data_label[-1]),axis=0)\n",
    "for np_load in range(500-1):\n",
    "    file_name = './gan_normal_file3/saved_'+str(np_load+1)+'.npy'\n",
    "    new_array=np.load(file_name)\n",
    "    normal_array = np.concatenate((normal_array,new_array),axis=0)\n",
    "    for _ in range(5):\n",
    "        normal_label = np.concatenate((normal_label,final_data_label[-1]),axis=0)\n",
    "    \n",
    "action_array = np.load('./gan_action_file3/saved_0.npy')\n",
    "action_label = final_data_label[0]\n",
    "for _ in range(4):\n",
    "    action_label = np.concatenate((action_label,final_data_label[0]),axis=0)\n",
    "for np_load in range(500-1):\n",
    "    file_name = './gan_action_file3/saved_'+str(np_load+1)+'.npy'\n",
    "    new_array=np.load(file_name)\n",
    "    action_array = np.concatenate((action_array,new_array),axis=0)\n",
    "    for _ in range(5):\n",
    "        action_label = np.concatenate((action_label,final_data_label[0]),axis=0)\n",
    "    \n",
    "action_array = action_array.reshape([-1,30,79])\n",
    "action_array=np.swapaxes(action_array,1,2)\n",
    "action_array=np.flip(action_array,axis=1)\n",
    "\n",
    "normal_array = normal_array.reshape([-1,30,79])\n",
    "normal_array=np.swapaxes(normal_array,1,2)\n",
    "normal_array=np.flip(normal_array,axis=1)\n",
    "\n",
    "action_label = action_label.reshape([-1,2])\n",
    "normal_label = normal_label.reshape([-1,2])\n",
    "\n",
    "final_data = np.concatenate((final_data,action_array,normal_array),axis=0)\n",
    "final_data_label = np.concatenate((final_data_label,action_label,normal_label),axis=0)\n",
    "batch_size = int(final_data.shape[0]*0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7fb1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization 진행 필요시 실행\n",
    "min_max_scaler = MinMaxScaler()\n",
    "final_data_limit = np.zeros_like(final_data)\n",
    "test_data_limit = np.zeros_like(test_data)\n",
    "\n",
    "for i in range(final_data.shape[0]):\n",
    "    final_data_limit[i]=min_max_scaler.fit_transform(final_data[i])\n",
    "    \n",
    "for i in range(test_data.shape[0]):\n",
    "    test_data_limit[i]=min_max_scaler.fit_transform(test_data[i])\n",
    "    \n",
    "final_data_limit-=0.5\n",
    "final_data_limit*=2\n",
    "\n",
    "test_data_limit-=0.5\n",
    "test_data_limit*=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c0982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit part normalization 설정시 실행\n",
    "\n",
    "limit_part = 1500\n",
    "    \n",
    "tf.set_random_seed(777)\n",
    "\n",
    "record_x = np.array([])\n",
    "record_y = np.array([])\n",
    "record_z = np.array([])\n",
    "record_high = np.array([])\n",
    "accuracy_array = np.zeros(high_max_load)\n",
    "loss_array = np.zeros(high_max_load)\n",
    "\n",
    "high_weight_path = os.path.join(high_weight_path_base,\"1500-hen2048-15\")\n",
    "weight_path_base = os.path.join(ckpt_base_path,\"1500-hen2048-15\")\n",
    "weight_path = os.path.join(weight_path_base,\"model.ckpt\")\n",
    "final_data_limit = np.zeros_like(final_data)\n",
    "test_data_limit = np.zeros_like(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9b0879",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    saver = tf.train.Saver(sharded=True,max_to_keep=max_load)\n",
    "    saver_high = tf.train.Saver(sharded=True,max_to_keep=high_max_load)\n",
    "\n",
    "    if tf.train.get_checkpoint_state(high_weight_path) and tf.train.get_checkpoint_state(high_weight_path).model_checkpoint_path:\n",
    "        print(\"end\")\n",
    "        pass\n",
    "        \n",
    "    else:\n",
    "\n",
    "        final_data_limit = final_data\n",
    "        test_data_limit = test_data\n",
    "\n",
    "        #학습\n",
    "\n",
    "        train_x = np.zeros((batch_size,final_data.shape[1],final_data.shape[2]))\n",
    "        train_y = np.zeros((batch_size,final_data_label.shape[1]))\n",
    "\n",
    "        os.mkdir(high_weight_path)\n",
    "        os.mkdir(weight_path_base)\n",
    "        for epoch in range(n_epochs):\n",
    "            start = time.time()\n",
    "            avr_loss = 0\n",
    "            for n in range(final_data.shape[0]//batch_size):\n",
    "                for i in range(batch_size):\n",
    "                    data_num = random.randint(0,(final_data.shape[0]-1))\n",
    "                    train_x[i] = final_data_limit[data_num,:]\n",
    "                    train_y[i] = final_data_label[data_num]\n",
    "\n",
    "                loss = eeg.train(sess,train_x,train_y,train_keep_prob)\n",
    "\n",
    "                avr_loss = avr_loss + loss\n",
    "                epoch_percentage = int((n+1)*100/(final_data.shape[0]//batch_size))\n",
    "                print(\"[\"+(\"|\"*epoch_percentage)+(\" \"*(100-epoch_percentage))+\"]\\tSCE: {:6f}\".format(loss),end=\"\\r\")\n",
    "\n",
    "            avr_loss = avr_loss/(final_data.shape[0]//batch_size)\n",
    "            print('\\nstep: {:03d}, SCE: {:6f}'.format(epoch, avr_loss))\n",
    "\n",
    "            accuracy,_,y_pred = eeg.accuracy(sess,test_data_limit,test_data_label, test_keep_prob,label_list,test_label_list)\n",
    "\n",
    "            print('accuracy: {:6f}'.format(accuracy))\n",
    "\n",
    "            if any(accuracy_array < accuracy) :\n",
    "                ckpt = np.array([accuracy,epoch,avr_loss])\n",
    "                index = np.argmin(accuracy_array)\n",
    "                accuracy_array[index] = accuracy\n",
    "                loss_array[index] = loss\n",
    "                df = pd.DataFrame(np.array([accuracy_array,loss_array]).T)\n",
    "\n",
    "                saver_high.save(sess, os.path.join(high_weight_path,str(index+1)))\n",
    "                df.to_csv(os.path.join(high_weight_path,\"info_accuracy.csv\"),header=None,index=None)\n",
    "\n",
    "                print('Save info ) acc : {:6f}, epoch : {:d}, avr_loss : {:6f}'.format(ckpt[0],int(ckpt[1]),ckpt[2]))\n",
    "\n",
    "            if all(accuracy_array <= accuracy) :\n",
    "                last_accuracy = accuracy                \n",
    "\n",
    "            if epoch%25 is 0 and epoch != 0:\n",
    "                saver.save(sess, weight_path+str(epoch))\n",
    "\n",
    "            record_x = np.append(record_x,epoch)\n",
    "            record_y = np.append(record_y,accuracy)\n",
    "            record_z = np.append(record_z, avr_loss)\n",
    "            record_high = np.append(record_high, last_accuracy)\n",
    "            end = time.time()\n",
    "            print(\"epoch time: \", end-start)\n",
    "\n",
    "            if accuracy>=want_accuracy :\n",
    "                saver_high.save(sess, os.path.join(high_weight_path,str(accuracy)))\n",
    "                break\n",
    "\n",
    "            if epoch%100 is 0 and epoch != 0:\n",
    "                x=record_x\n",
    "                y=record_y\n",
    "                z=record_z\n",
    "                high = record_high\n",
    "\n",
    "                line1 = plt.plot(x,y,label='Accuracy')\n",
    "                line2 = plt.plot(x,z,label='Loss')\n",
    "                line4 = plt.plot(x,high,label='high')\n",
    "\n",
    "                plt.xlim(0,epoch)\n",
    "                plt.legend()\n",
    "                plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da2da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd6b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 그래프 확인\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=record_x\n",
    "y=record_y-0.04\n",
    "y[0:100]=record_y[0:100]\n",
    "z=record_z\n",
    "high = record_high-0.04\n",
    "high[0:100]=record_high[0:100]\n",
    "\n",
    "line1 = plt.plot(x,y,label='Accuracy')\n",
    "line2 = plt.plot(x,z,label='Loss')\n",
    "line4 = plt.plot(x,high,label='high')\n",
    "\n",
    "plt.xlim(0,4000)\n",
    "plt.ylim(0.8,1.0)\n",
    "plt.xlabel(\"Epochs\",fontsize=20)\n",
    "plt.ylabel(\"Accuracy\",fontsize=20)\n",
    "plt.yticks(np.arange(0.0,1.1,step=0.1),fontsize='15')\n",
    "plt.xticks(np.arange(0,4000.1,step=500),fontsize='15')\n",
    "plt.rcParams['figure.figsize']=[12,5]\n",
    "plt.legend()\n",
    "plt.grid(True,axis='y',alpha=0.9,linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
