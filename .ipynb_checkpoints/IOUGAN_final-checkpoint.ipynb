{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abd165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from scipy import io\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import gzip\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "import brain_python6 as bp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "n_times = 201\n",
    "n_frequency = 79\n",
    "n_outputs = 2\n",
    "\n",
    "last_neurons = 40\n",
    "n_neurons = [40,40,last_neurons]\n",
    "\n",
    "want_accuracy = 1.0\n",
    "last_accuracy = 0\n",
    "\n",
    "max_load = 5\n",
    "high_max_load = 10\n",
    "\n",
    "load_number = ''\n",
    "\n",
    "important_index = [105,125]\n",
    "normal_range_index = [20,180]\n",
    "window = 30\n",
    "step = 1\n",
    "\n",
    "data_base_path = \"./brain_data8~50\"\n",
    "\n",
    "eeg = bp.brain_python(n_times,n_frequency,window,n_outputs)\n",
    "label_list,_,_ = eeg.label_info(data_base_path)\n",
    "\n",
    "train_data,train_data_label,_ = eeg.preprocessing(data_base_path)\n",
    "\n",
    "final_data, final_data_label = eeg.data_multiple(train_data,train_data_label,label_list,important_index,normal_range_index,step)\n",
    "\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229e1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내부 교점 탐색 함수 설정\n",
    "def intersection(linex1,liney1,linex2,liney2):\n",
    "    f1 = (linex1[1]-linex1[0])*(liney2[0]-liney1[0])-(liney1[1]-liney1[0])*(linex2[0]-linex1[0])\n",
    "    f2 = (linex1[1]-linex1[0])*(liney2[1]-liney1[0])-(liney1[1]-liney1[0])*(linex2[1]-linex1[0])\n",
    "    f3 = (linex2[1]-linex2[0])*(liney1[0]-liney2[0])-(liney2[1]-liney2[0])*(linex1[0]-linex2[0])\n",
    "    f4 = (linex2[1]-linex2[0])*(liney1[1]-liney2[0])-(liney2[1]-liney2[0])*(linex1[1]-linex2[0])\n",
    "    \n",
    "    if f1*f2<0 and f3*f4<0:\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "        \n",
    "def intersection_dot(linex1,liney1,linex2,liney2):\n",
    "        m1 = (liney1[1]-liney1[0])/(linex1[1]-linex1[0])\n",
    "        m2 = (liney2[1]-liney2[0])/(linex2[1]-linex2[0])\n",
    "        cx = (linex1[0]*m1-liney1[0]-linex2[0]*m2+liney2[0])/(m1-m2)\n",
    "        cy = m1*(cx-linex1[0])+liney1[0]\n",
    "        return np.array([[cx, cy]],float)\n",
    "        \n",
    "def intersection_inner(linex,liney,dot,max_dot):\n",
    "        f1 = (linex[1]-linex[0])*(dot[1]-liney[0])-(liney[1]-liney[0])*(dot[0]-linex[0])\n",
    "        f2 = (linex[1]-linex[0])*(dot[1]-liney[0])-(liney[1]-liney[0])*(max_dot-linex[0])\n",
    "        f3 = (max_dot-dot[0])*(liney[0]-dot[1])-(dot[1]-dot[1])*(linex[0]-dot[0])\n",
    "        f4 = (max_dot-dot[0])*(liney[1]-dot[1])-(dot[1]-dot[1])*(linex[1]-dot[0])\n",
    "\n",
    "        if f1*f2<0 and f3*f4<0:\n",
    "            return 1\n",
    "        else :\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d9637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA 함수 설정\n",
    "def pca_data(input_data):\n",
    "    final_data = input_data\n",
    "    # plus\n",
    "    cut_times = 8\n",
    "    stride = 2\n",
    "    cluster_data = np.zeros([final_data.shape[0]*((final_data.shape[1]-cut_times+stride)//stride),cut_times,final_data.shape[2]])\n",
    "\n",
    "    cluster_number = 0\n",
    "    for input_data in final_data:\n",
    "        for i in range(0,final_data.shape[1]-cut_times+stride,stride):\n",
    "            cluster_data[cluster_number]=input_data[i:i+cut_times]\n",
    "            cluster_number += 1\n",
    "\n",
    "    action_cluster_data = cluster_data\n",
    "    # action_cluster_data = cluster_data[:sum(train_data_label==[1,0])[0]*train_data.shape[1]//cut_times]\n",
    "\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # action_cluster_data=np.transpose(action_cluster_data,(0,2,1))\n",
    "\n",
    "    pca_1 = PCA(n_components=1)\n",
    "    pca_2 = PCA(n_components=2)\n",
    "\n",
    "    pc_data = np.zeros([action_cluster_data.shape[0],action_cluster_data.shape[1],1])\n",
    "    for i in range(action_cluster_data.shape[0]):\n",
    "        pc_data[i] = pca_1.fit_transform(action_cluster_data[i])\n",
    "        \n",
    "    pc_data = pc_data.reshape(pc_data.shape[0],pc_data.shape[1])\n",
    "    pc_data = scaler.fit_transform(pc_data)\n",
    "\n",
    "    pc = pca_2.fit_transform(pc_data)\n",
    "    \n",
    "    #normal outlier\n",
    "\n",
    "    clf = LocalOutlierFactor(n_neighbors=int(pc.shape[0]*0.005),contamination='auto')\n",
    "    outlier_index = clf.fit_predict(pc)\n",
    "    pc = np.delete(pc,np.where(outlier_index==-1),axis=0)\n",
    "    \n",
    "    return pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b22ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IOU Score 함수 설정\n",
    "def IOU_score(pc1,pc2):\n",
    "    pc1_hull = ConvexHull(pc1).simplices\n",
    "    pc2_hull = ConvexHull(pc2).simplices\n",
    "\n",
    "    IOU_dot = np.empty((0,2),float)\n",
    "    for i in np.unique(pc2_hull):\n",
    "        count=0\n",
    "        for simplex1 in pc1_hull:\n",
    "            count+=intersection_inner(pc1[simplex1,0],pc1[simplex1,1],pc2[i],9999)\n",
    "        if count%2 == 1:\n",
    "            IOU_dot = np.append(IOU_dot, pc2[i].reshape(-1,2), axis=0)\n",
    "\n",
    "    for i in np.unique(pc1_hull):\n",
    "        count=0\n",
    "        for simplex2 in pc2_hull:\n",
    "            count+=intersection_inner(pc2[simplex2,0],pc2[simplex2,1],pc1[i],9999)\n",
    "        if count%2 == 1:\n",
    "            IOU_dot = np.append(IOU_dot, pc1[i].reshape(-1,2), axis=0)\n",
    "\n",
    "    for simplex1 in pc1_hull:\n",
    "\n",
    "        for simplex2 in pc2_hull:\n",
    "\n",
    "            if intersection(pc1[simplex1,0],pc1[simplex1,1],pc2[simplex2,0],pc2[simplex2,1]) == 1:\n",
    "                intersection_point=intersection_dot(pc1[simplex1,0],pc1[simplex1,1],pc2[simplex2,0],pc2[simplex2,1])\n",
    "                IOU_dot = np.append(IOU_dot,intersection_point,axis=0)\n",
    "\n",
    "    for simplex1 in pc1_hull:\n",
    "        plt.plot(pc1[simplex1,0],pc1[simplex1,1],'r--')\n",
    "\n",
    "    for simplex2 in pc2_hull:\n",
    "        plt.plot(pc2[simplex2,0],pc2[simplex2,1],'g--')\n",
    "\n",
    "    for pointing in IOU_dot:\n",
    "        plt.plot(pointing[0],pointing[1],'ro')\n",
    "        \n",
    "    plt.scatter(pc1[:,0],pc1[:,1],marker=\".\",s=50)\n",
    "    plt.scatter(pc2[:,0],pc2[:,1],marker=\"+\",s=10)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    IOU_score=ConvexHull(IOU_dot).volume/(ConvexHull(pc1).volume+ConvexHull(pc2).volume-ConvexHull(IOU_dot).volume)\n",
    "    \n",
    "    return IOU_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d079dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Model 구현\n",
    "Generator = tf.keras.Sequential()\n",
    "Generator.add(layers.Dense(7*19*256,use_bias=False,input_shape=(100,)))\n",
    "Generator.add(layers.BatchNormalization())\n",
    "Generator.add(layers.LeakyReLU())\n",
    "\n",
    "Generator.add(layers.Reshape((7,19,256)))\n",
    "\n",
    "Generator.add(layers.Conv2DTranspose(128,(5,5),strides=(1,1),padding='same',use_bias=False))\n",
    "Generator.add(layers.BatchNormalization())\n",
    "Generator.add(layers.LeakyReLU())\n",
    "\n",
    "Generator.add(layers.Conv2DTranspose(64,(5,5),strides=(2,2),padding='same',use_bias=False))\n",
    "Generator.add(layers.BatchNormalization())\n",
    "Generator.add(layers.LeakyReLU())\n",
    "\n",
    "Generator.add(layers.Conv2DTranspose(1,(4,5),strides=(2,2),padding='valid',use_bias=False,activation='tanh'))\n",
    "# Generator.add(layers.Reshape((30,79)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6062f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator Model 구현\n",
    "Discriminator = tf.keras.Sequential()\n",
    "Discriminator.add(layers.Conv2D(64, (5,5),strides=(2,2),padding='same',input_shape=[30,79,1]))\n",
    "\n",
    "Discriminator.add(layers.LeakyReLU())\n",
    "Discriminator.add(layers.Dropout(0.3))\n",
    "\n",
    "Discriminator.add(layers.Conv2D(128, (5,5),strides = (2,2),padding = 'same'))\n",
    "Discriminator.add(layers.LeakyReLU())\n",
    "Discriminator.add(layers.Dropout(0.3))\n",
    "\n",
    "Discriminator.add(layers.Flatten())\n",
    "Discriminator.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Optimizer\n",
    "Doptimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "Goptimizer = tf.keras.optimizers.Adam(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e571a52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise 함수, 학습 함수 설정\n",
    "def get_noise(batch_size,n_noise):\n",
    "    return tf.random.normal([batch_size,n_noise])\n",
    "\n",
    "def train_step(inputs):\n",
    "\n",
    "    with tf.GradientTape() as t1, tf.GradientTape() as t2:\n",
    "        # 잡음으로부터 이미지 생성\n",
    "        G = Generator(get_noise(inputs.shape[0],100))\n",
    "#         G = Generator(noise)\n",
    "        # 판별자 입력\n",
    "        Z = Discriminator(G)\n",
    "        R = Discriminator(inputs)   \n",
    "        # 손실 함수 연산\n",
    "        cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        loss_D = cross_entropy(tf.ones_like(R),R)+cross_entropy(tf.zeros_like(Z),Z)\n",
    "        loss_G = cross_entropy(tf.ones_like(Z),Z)\n",
    "\n",
    "    # 판별자 업데이트      \n",
    "    Dgradients = t1.gradient(loss_D, Discriminator.trainable_variables)\n",
    "    Doptimizer.apply_gradients(zip(Dgradients, Discriminator.trainable_variables))\n",
    "    # 생성자 업데이트\n",
    "    Ggradients = t2.gradient(loss_G,Generator.trainable_variables)\n",
    "    Goptimizer.apply_gradients(zip(Ggradients, Generator.trainable_variables)) \n",
    "    return loss_D, loss_G,G,Z,R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9f73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_limit=final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecfac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 사이즈\n",
    "total_batch = int(final_data_limit.shape[0]/batch_size) \n",
    "np_load_count = 0\n",
    "number_of_load = 200\n",
    "want_data = 2000\n",
    "stop_per = 0\n",
    "\n",
    "for epoch in tf.range(20000):\n",
    "    for i in tf.range(total_batch):\n",
    "        batch_input = final_data_limit[i*batch_size:(i+1)*batch_size]\n",
    "        batch_input = np.reshape(batch_input,[-1,30,79,1])\n",
    "\n",
    "        l_D,l_G,G_v,Z_v,R_v=train_step(batch_input)\n",
    "        \n",
    "        \n",
    "# 생성된 이미지\n",
    "    if epoch%1==0:\n",
    "        G = Generator(get_noise(1,100))\n",
    "        \n",
    "        pc1=pca_data(final_data_limit)\n",
    "        pc2=pca_data(np.reshape(Generator(get_noise(2000,100)),(-1,30,79)))\n",
    "        IOU = IOU_score(pc1,pc2)\n",
    "        if IOU>0.88:\n",
    "            for np_load in range(number_of_load):\n",
    "                G = Generator(get_noise(5,100)) # 5개를 하나의 numpy 파일에 저장\n",
    "                file_name = './gan_action_file/saved_'+str(np_load+np_load_count)\n",
    "                np.save(file_name,G)\n",
    "                stop_per = np_load+np_load_count\n",
    "            np_load_count += number_of_load\n",
    "\n",
    "        plt.imshow(np.reshape(G[0],(30,79)),interpolation=\"nearest\",cmap='gray')\n",
    "        plt.pause(0.001)\n",
    "        print(\"l_D:\",str(l_D))\n",
    "        print(\"l_G:\",str(l_G))\n",
    "        print(\"Z_avr:\",str(sum(Z_v)/Z_v.shape[0]))\n",
    "        print(\"IOU_score:\",str(IOU))\n",
    "        plt.show()\n",
    "        \n",
    "    if stop_per >= want_data-1:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
